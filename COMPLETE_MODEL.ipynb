{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fd6a13d-973d-407c-af8d-6ad0d5d2cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 705 entries, 0 to 704\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   name                705 non-null    object \n",
      " 1   location            705 non-null    object \n",
      " 2   date                705 non-null    object \n",
      " 3   rating              705 non-null    float64\n",
      " 4   review              705 non-null    object \n",
      " 5   image_links         705 non-null    object \n",
      " 6   cleaned_review      705 non-null    object \n",
      " 7   word_count          705 non-null    int64  \n",
      " 8   char_count          705 non-null    int64  \n",
      " 9   sentiment_category  705 non-null    object \n",
      " 10  normalized_rating   705 non-null    float64\n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 60.7+ KB\n",
      "None\n",
      "       name           location        date  rating  \\\n",
      "0     Helen  Wichita Falls, TX  2023-09-13     5.0   \n",
      "1  Courtney         Apopka, FL  2023-07-16     5.0   \n",
      "2  Daynelle  Cranberry Twp, PA  2023-07-05     5.0   \n",
      "3    Taylor        Seattle, WA  2023-05-26     5.0   \n",
      "4   Tenessa        Gresham, OR  2023-01-22     5.0   \n",
      "\n",
      "                                              review  \\\n",
      "0  Amber and LaDonna at the Starbucks on Southwes...   \n",
      "1  ** at the Starbucks by the fire station on 436...   \n",
      "2  I just wanted to go out of my way to recognize...   \n",
      "3  Me and my friend were at Starbucks and my card...   \n",
      "4  Iâ€™m on this kick of drinking 5 cups of warm wa...   \n",
      "\n",
      "                                         image_links  \\\n",
      "0                                      ['No Images']   \n",
      "1                                      ['No Images']   \n",
      "2  ['https://media.consumeraffairs.com/files/cach...   \n",
      "3                                      ['No Images']   \n",
      "4  ['https://media.consumeraffairs.com/files/cach...   \n",
      "\n",
      "                                      cleaned_review  word_count  char_count  \\\n",
      "0  amber and ladonna at the starbucks on southwes...          59         322   \n",
      "1  at the starbucks by the fire station on in alt...         101         529   \n",
      "2  i just wanted to go out of my way to recognize...          70         343   \n",
      "3  me and my friend were at starbucks and my card...          84         409   \n",
      "4  im on this kick of drinking cups of warm water...          73         393   \n",
      "\n",
      "  sentiment_category  normalized_rating  \n",
      "0           Positive                1.0  \n",
      "1           Positive                1.0  \n",
      "2           Positive                1.0  \n",
      "3           Positive                1.0  \n",
      "4           Positive                1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\idehe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\idehe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_review sentiment_category\n",
      "0  amber ladonna starbucks southwest parkway alwa...           Positive\n",
      "1  starbucks fire station altamonte springs fl ma...           Positive\n",
      "2  wanted go way recognize starbucks employee bil...           Positive\n",
      "3  friend starbucks card didnt work thankful work...           Positive\n",
      "4  im kick drinking cups warm water work instacar...           Positive\n",
      "5  correct order times never got right manager ca...           Negative\n",
      "6  tried starbucks several different times differ...           Negative\n",
      "7  starbucks near launched new fall foods beverag...           Negative\n",
      "8  ordered online reisterstown rd st thomas sc ga...           Negative\n",
      "9  staff smythe st superstore location fredericto...           Negative\n",
      "Label Encoding Mapping: {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
      "                                      cleaned_review sentiment_category  \\\n",
      "0  amber ladonna starbucks southwest parkway alwa...           Positive   \n",
      "1  starbucks fire station altamonte springs fl ma...           Positive   \n",
      "2  wanted go way recognize starbucks employee bil...           Positive   \n",
      "3  friend starbucks card didnt work thankful work...           Positive   \n",
      "4  im kick drinking cups warm water work instacar...           Positive   \n",
      "5  correct order times never got right manager ca...           Negative   \n",
      "6  tried starbucks several different times differ...           Negative   \n",
      "7  starbucks near launched new fall foods beverag...           Negative   \n",
      "8  ordered online reisterstown rd st thomas sc ga...           Negative   \n",
      "9  staff smythe st superstore location fredericto...           Negative   \n",
      "\n",
      "  keyword_sentiment  \n",
      "0          positive  \n",
      "1          positive  \n",
      "2          positive  \n",
      "3           unknown  \n",
      "4          positive  \n",
      "5           unknown  \n",
      "6           unknown  \n",
      "7          negative  \n",
      "8          negative  \n",
      "9          negative  \n",
      "Logistic Regression Performance with Keyword Feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91       103\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.83      0.63      0.72        30\n",
      "\n",
      "    accuracy                           0.85       141\n",
      "   macro avg       0.56      0.54      0.54       141\n",
      "weighted avg       0.80      0.85      0.82       141\n",
      "\n",
      "Confusion Matrix:\n",
      " [[101   0   2]\n",
      " [  6   0   2]\n",
      " [ 11   0  19]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idehe\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\idehe\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\idehe\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "## Load and Inspect Dataset\n",
    "df = pd.read_csv(\"sentiment_cleaned_customer_reviews.csv\")\n",
    "\n",
    "# Display basic information\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "#Clean the Review Text\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove multiple spaces\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    tokens = word_tokenize(text)  # Tokenize words\n",
    "    text = ' '.join([word for word in tokens if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Apply function to cleaned_review column\n",
    "df['cleaned_review'] = df['cleaned_review'].astype(str).apply(clean_text)\n",
    "\n",
    "# Check results\n",
    "print(df[['cleaned_review', 'sentiment_category']].head(10))\n",
    "\n",
    "#Encode Sentiment Labels\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment_encoded'] = label_encoder.fit_transform(df['sentiment_category'])\n",
    "\n",
    "# Display mapping\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Encoding Mapping:\", label_mapping)\n",
    "\n",
    "##TF-IDF Vectorization for Logistic Regression\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Keep top 5000 words\n",
    "X_tfidf = vectorizer.fit_transform(df['cleaned_review']).toarray()\n",
    "y = df['sentiment_encoded']\n",
    "\n",
    "\n",
    "# Define keyword-based classification rules\n",
    "positive_keywords = {'excellent', 'great', 'amazing', 'awesome', 'good', 'love', 'best', 'fantastic', 'wonderful', 'clean', 'warm', 'friendly', \n",
    "                    'delight', 'smile', 'authentic', 'awesome', 'fabulous'}\n",
    "negative_keywords = {'bad', 'horrible', 'awful', 'worst', 'terrible', 'poor', 'hate', 'disappointed', 'wrong', 'watery', 'over priced', 'unhealthy'}\n",
    "neutral_keywords = {'okay', 'average', 'fine', 'decent', 'satisfactory', 'neutral', 'understandable', 'mild', 'subtle', 'acceptable', 'lukewarm'}\n",
    "\n",
    "def keyword_classification(text):\n",
    "    words = set(text.split())  # Convert text into a set of words\n",
    "    if words & positive_keywords:\n",
    "        return 'positive'\n",
    "    elif words & negative_keywords:\n",
    "        return 'negative'\n",
    "    elif words & neutral_keywords:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'unknown'  # If no matching keywords are found\n",
    "\n",
    "# Apply the keyword classification function\n",
    "df['keyword_sentiment'] = df['cleaned_review'].apply(keyword_classification)\n",
    "\n",
    "# Encode the keyword-based sentiment labels\n",
    "df['keyword_sentiment_encoded'] = label_encoder.fit_transform(df['keyword_sentiment'])\n",
    "\n",
    "# Compare keyword-based sentiment classification with ML classification\n",
    "print(df[['cleaned_review', 'sentiment_category', 'keyword_sentiment']].head(10))\n",
    "\n",
    "# Ensure `keyword_sentiment_encoded` is a NumPy array\n",
    "keyword_sentiment_encoded = df['keyword_sentiment_encoded'].values.reshape(-1, 1)\n",
    "\n",
    "# Combine TF-IDF features with keyword sentiment encoding\n",
    "X_combined = np.hstack((X_tfidf, keyword_sentiment_encoded))\n",
    "\n",
    "# Train-test split (make sure X_train and X_test have the same number of features)\n",
    "X_train_combined, X_test_combined, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE (only to training data)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_combined, y_train)\n",
    "\n",
    "\n",
    "# Initialize and Train Logistic Regression Model\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions (Ensure X_test_combined is used, not X_test)\n",
    "y_pred_log_combined = log_model.predict(X_test_combined)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression Performance with Keyword Feature:\")\n",
    "print(classification_report(y_test, y_pred_log_combined))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log_combined))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79a39546-a14a-44f2-a244-aaa7a36881c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, vectorizer, and label encoder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained logistic regression model\n",
    "joblib.dump(log_model, 'sentiment_model.pkl')\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# Save the Label Encoder (for keyword_sentiment_encoded)\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "print(\"Model, vectorizer, and label encoder saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c504544-cdb6-4589-b761-ae86e1876e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the saved model, vectorizer, and label encoder\n",
    "loaded_model = joblib.load('sentiment_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "loaded_label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Define the keyword-based classification function\n",
    "positive_keywords = {'excellent', 'great', 'amazing', 'awesome', 'good', 'love', 'best', 'fantastic', 'wonderful', 'clean', 'warm', 'friendly', \n",
    "                    'delight', 'smile', 'authentic', 'awesome', 'fabulous'}\n",
    "negative_keywords = {'bad', 'horrible', 'awful', 'worst', 'terrible', 'poor', 'hate', 'disappointed', 'wrong', 'watery', 'over priced', 'unhealthy'}\n",
    "neutral_keywords = {'okay', 'average', 'fine', 'decent', 'satisfactory', 'neutral', 'understandable', 'mild', 'subtle', 'acceptable', 'lukewarm'}\n",
    "\n",
    "def keyword_classification(text):\n",
    "    words = set(text.lower().split())  # Convert text into a set of words\n",
    "    if words & positive_keywords:\n",
    "        return 'positive'\n",
    "    elif words & negative_keywords:\n",
    "        return 'negative'\n",
    "    elif words & neutral_keywords:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'unknown'  # If no matching keywords are found\n",
    "\n",
    "# Example prediction\n",
    "sample_review = [\"The product quality is excellent and I love it!\"]\n",
    "\n",
    "# Vectorize the input text\n",
    "sample_vectorized = loaded_vectorizer.transform(sample_review).toarray()\n",
    "\n",
    "# Apply keyword classification\n",
    "sample_keyword_sentiment = keyword_classification(sample_review[0])\n",
    "\n",
    "# Encode the keyword-based classification\n",
    "sample_keyword_encoded = loaded_label_encoder.transform([sample_keyword_sentiment])[0]\n",
    "\n",
    "# Combine both features\n",
    "sample_combined = np.hstack((sample_vectorized, np.array([[sample_keyword_encoded]])))\n",
    "\n",
    "# Make a prediction\n",
    "prediction = loaded_model.predict(sample_combined)\n",
    "\n",
    "print(\"Predicted Sentiment:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac416b2b-1a36-4f12-9dea-7b28b023ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python sentiment_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc19165e-1db0-4897-91df-a3ff97a89c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 2}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:5000/predict\"\n",
    "data = {\"review\": \"The coffee is amazing, and the customer service is excellent. I love it.\"}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())  # Should return {\"sentiment\": \"2\"}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
